{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "523ac5e4-2110-446c-996f-9620fb12b3bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of image paths: 30\n",
      "\n",
      "Randomly selected 5 image paths and labels:\n",
      "Path: ./dataset_agri\\class_1_agri\\image_6.jpg, Label: 1\n",
      "Path: ./dataset_agri\\class_0_non_agri\\image_3.jpg, Label: 0\n",
      "Path: ./dataset_agri\\class_0_non_agri\\image_6.jpg, Label: 0\n",
      "Path: ./dataset_agri\\class_1_agri\\image_11.jpg, Label: 1\n",
      "Path: ./dataset_agri\\class_0_non_agri\\image_5.jpg, Label: 0\n",
      "\n",
      "Task 3: Batch of data generated.\n",
      "Batch images shape: (8, 64, 64, 3)\n",
      "Batch labels: [1 0 1 1 0 0 1 0]\n",
      "\n",
      "Task 4: Validation data batch generated.\n",
      "Validation images batch shape: (6, 64, 64, 3)\n",
      "Validation labels batch: [0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# Set up dummy directories and files for demonstration\n",
    "base_dir = './dataset_agri'\n",
    "os.makedirs(os.path.join(base_dir, 'class_0_non_agri'), exist_ok=True)\n",
    "os.makedirs(os.path.join(base_dir, 'class_1_agri'), exist_ok=True)\n",
    "\n",
    "for i in range(15):\n",
    "    with open(os.path.join(base_dir, 'class_0_non_agri', f'image_{i}.jpg'), 'w') as f:\n",
    "        f.write('dummy content')\n",
    "    with open(os.path.join(base_dir, 'class_1_agri', f'image_{i}.jpg'), 'w') as f:\n",
    "        f.write('dummy content')\n",
    "\n",
    "# Task 1: Create the list \"all_image_paths\"\n",
    "non_agri_dir = os.path.join(base_dir, 'class_0_non_agri')\n",
    "agri_dir = os.path.join(base_dir, 'class_1_agri')\n",
    "\n",
    "all_image_paths_non_agri = [os.path.join(non_agri_dir, f) for f in os.listdir(non_agri_dir)]\n",
    "all_image_paths_agri = [os.path.join(agri_dir, f) for f in os.listdir(agri_dir)]\n",
    "\n",
    "all_image_paths = all_image_paths_non_agri + all_image_paths_agri\n",
    "print(f\"Total number of image paths: {len(all_image_paths)}\")\n",
    "\n",
    "# Task 2: Create a temporary list \"temp\"\n",
    "labels_non_agri = [0] * len(all_image_paths_non_agri)\n",
    "labels_agri = [1] * len(all_image_paths_agri)\n",
    "all_labels = labels_non_agri + labels_agri\n",
    "\n",
    "temp = list(zip(all_image_paths, all_labels))\n",
    "\n",
    "print(\"\\nRandomly selected 5 image paths and labels:\")\n",
    "random_selection = random.sample(temp, 5)\n",
    "for path, label in random_selection:\n",
    "    print(f\"Path: {path}, Label: {label}\")\n",
    "\n",
    "# Task 3: Generate a batch of data\n",
    "def custom_data_generator(data_list, batch_size):\n",
    "    \"\"\"\n",
    "    This is a dummy generator that yields batches of dummy data.\n",
    "    In a real-world scenario, you would load and process the images here.\n",
    "    \"\"\"\n",
    "    num_samples = len(data_list)\n",
    "    while True:\n",
    "        # Shuffle the data\n",
    "        random.shuffle(data_list)\n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            batch_samples = data_list[offset:offset + batch_size]\n",
    "            \n",
    "            # Dummy placeholders for actual image and label data\n",
    "            # In a real generator, you'd load images and corresponding labels\n",
    "            batch_images = np.random.rand(len(batch_samples), 64, 64, 3) \n",
    "            batch_labels = np.array([label for path, label in batch_samples])\n",
    "            \n",
    "            yield (batch_images, batch_labels)\n",
    "\n",
    "batch_size = 8\n",
    "data_generator = custom_data_generator(temp, batch_size=batch_size)\n",
    "images_batch, labels_batch = next(data_generator)\n",
    "\n",
    "print(f\"\\nTask 3: Batch of data generated.\")\n",
    "print(f\"Batch images shape: {images_batch.shape}\")\n",
    "print(f\"Batch labels: {labels_batch}\")\n",
    "\n",
    "# Task 4: Create validation data\n",
    "# Split the original data into training and validation sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data, val_data = train_test_split(temp, test_size=0.2, random_state=42)\n",
    "\n",
    "val_batch_size = 8\n",
    "val_data_generator = custom_data_generator(val_data, batch_size=val_batch_size)\n",
    "val_images_batch, val_labels_batch = next(val_data_generator)\n",
    "\n",
    "print(f\"\\nTask 4: Validation data batch generated.\")\n",
    "print(f\"Validation images batch shape: {val_images_batch.shape}\")\n",
    "print(f\"Validation labels batch: {val_labels_batch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b99f550-2001-4122-b25a-5784b7e9daae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
